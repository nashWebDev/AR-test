<!DOCTYPE html>
<html>
    <script src="https://aframe.io/releases/1.6.0/aframe.min.js"></script>
    <!-- we import arjs version without NFT but with marker + location based support -->
    <script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js"></script>
    <body style="margin : 0px; overflow: hidden;">
        <a-scene embedded arjs>
        <a-marker preset="hiro">
            <!-- we use cors proxy to avoid cross-origin problems ATTENTION! you need to set up your server -->
<a-entity id="model_here"
            
            position="0 0 0"
            scale="0.1 0.1 0.1"
    gltf-model = "newtest.gltf"
            ></a-entity>
        </a-marker>
        <a-entity camera>
            <div id="text_here"></div>
        </a-entity>
        </a-scene>

        <script>
            var textHolder = document.querySelector('#text_here');

            var modelholder = document.querySelector('#model_here');
            document.addEventListener('DOMContentLoaded', () => {
                modelholder.attributes['gltf-model']= "newtest.gltf"
            });
            
            document.addEventListener('markerFound', () => {
                 setTimeout(() => {

                    modelholder.attributes['gltf-model'].value = "lady.glb"; 
                    textHolder.innerHTML = "Marker Found! Model should have Loaded.";
                    
                    
                 }, timeout = 1000);
            });
        </script>
    </body>
</html>

<!-- <html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image tracker</title>

    <!-- import aframe and then ar.js with image tracking / location based features -->
<!-- <script src="https://cdn.jsdelivr.net/gh/aframevr/aframe@1c2407b26c61958baa93967b5412487cd94b290b/dist/aframe-master.min.js"></script>
<script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js"></script>

<style>
  .arjs-loader {
    height: 100%;
    width: 100%;
    position: absolute;
    top: 0;
    left: 0;
    background-color: rgba(0, 0, 0, 0.8);
    z-index: 9999;
    display: flex;
    justify-content: center;
    align-items: center;
  }

  .arjs-loader div {
    text-align: center;
    font-size: 1.25em;
    color: white;
  }
</style> 
</head>
<body style="margin : 0px; overflow: hidden;">-->
  <!-- minimal loader shown until image descriptors are loaded. Loading may take a while according to the device computational power -->
<!--   <div class="arjs-loader">
    <div>Loading, please wait...</div>
  </div> -->

  <!-- a-frame scene -->
<!--   <a-scene
    vr-mode-ui="enabled: false;"
    renderer="logarithmicDepthBuffer: true;"
    embedded
    arjs="trackingMethod: best; sourceType: webcam;debugUIEnabled: false;"
  > -->
    <!-- a-nft is the anchor that defines an Image Tracking entity -->
    <!-- on 'url' use the path to the Image Descriptors created before. -->
    <!-- the path should end with the name without the extension e.g. if file is 'pinball.fset' the path should end with 'pinball' -->
<!--     <a-nft
      type="nft"
      url="AR-test/exported_qrcode_images/exported_qrcode_image"
      smooth="true"
      smoothCount="10"
      smoothTolerance=".01"
      smoothThreshold="5"
    > -->
      <!-- as a child of the a-nft entity, you can define the content to show. here's a GLTF model entity -->
<!--       <a-entity
        gltf-model="lady.glb"
        scale="5 5 5"
        position="50 150 0"
      >
      </a-entity>
    </a-nft>
    <!-- static camera that moves according to the device movemenents -->
<!--     <a-entity camera></a-entity>
  </a-scene>
</body>
</html> -->
